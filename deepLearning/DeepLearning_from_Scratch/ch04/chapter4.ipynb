{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.pardir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시그모이드(sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 소프트맥스(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 크로스 엔트로피(cross entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수치 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _numerical_gradient_1d(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x) # f(x+h)\n",
    "        \n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) # f(x-h)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, X):\n",
    "    if X.ndim == 1:\n",
    "        return _numerical_gradient_1d(f, X)\n",
    "    else:\n",
    "        grad = np.zeros_like(X)\n",
    "        \n",
    "        for idx, x in enumerate(X):\n",
    "            grad[idx] = _numerical_gradient_1d(f, x)\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2층 신경망 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.params['W1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.params['b1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.params['W2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.params['b2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "y = net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00098635, 0.00105182, 0.00099471, 0.00094116, 0.0010073 ,\n",
       "        0.00098078, 0.00100851, 0.00101994, 0.00099384, 0.0010164 ],\n",
       "       [0.00098599, 0.00105225, 0.00099292, 0.00093747, 0.00100684,\n",
       "        0.00097866, 0.00100609, 0.00101812, 0.00099574, 0.0010148 ],\n",
       "       [0.00098918, 0.00105451, 0.0009974 , 0.00093899, 0.00100687,\n",
       "        0.00098164, 0.00100804, 0.00101887, 0.00099599, 0.00101482],\n",
       "       [0.00098654, 0.00105505, 0.00099139, 0.00093951, 0.00100749,\n",
       "        0.00098169, 0.0010086 , 0.00101634, 0.00099599, 0.00101655],\n",
       "       [0.00098734, 0.00105215, 0.00099515, 0.00094169, 0.00100683,\n",
       "        0.00098183, 0.00100806, 0.0010225 , 0.0009966 , 0.00101667],\n",
       "       [0.00098623, 0.0010544 , 0.0009951 , 0.00094157, 0.00100791,\n",
       "        0.00098036, 0.00100562, 0.00102093, 0.00099356, 0.00101655],\n",
       "       [0.0009848 , 0.00105432, 0.00099737, 0.00094179, 0.00100673,\n",
       "        0.00098074, 0.00100472, 0.00102041, 0.0009962 , 0.00101654],\n",
       "       [0.00098885, 0.00105147, 0.00099653, 0.00094142, 0.00100998,\n",
       "        0.00098689, 0.00100514, 0.00102043, 0.00099544, 0.00101874],\n",
       "       [0.00098821, 0.00105142, 0.00099482, 0.00094183, 0.00100818,\n",
       "        0.00098068, 0.00100973, 0.00102027, 0.00099685, 0.0010127 ],\n",
       "       [0.00098542, 0.00105252, 0.00098981, 0.00094034, 0.00100667,\n",
       "        0.00098003, 0.00100551, 0.00102307, 0.00099272, 0.00101767],\n",
       "       [0.00098815, 0.00104836, 0.00099505, 0.00093966, 0.00100808,\n",
       "        0.0009795 , 0.00100618, 0.00102044, 0.00099628, 0.00101589],\n",
       "       [0.00099092, 0.00105143, 0.00099269, 0.0009416 , 0.00100835,\n",
       "        0.0009836 , 0.00100582, 0.00102036, 0.00099876, 0.00101574],\n",
       "       [0.00098839, 0.00105173, 0.00099614, 0.00094253, 0.00100647,\n",
       "        0.00098132, 0.00100875, 0.00102098, 0.00099496, 0.00101582],\n",
       "       [0.00098484, 0.00105192, 0.00099593, 0.00094256, 0.00100838,\n",
       "        0.00097936, 0.00100398, 0.00101892, 0.00099688, 0.00101621],\n",
       "       [0.00098656, 0.00105177, 0.00099298, 0.00094427, 0.00100696,\n",
       "        0.00098278, 0.0010081 , 0.00101626, 0.0009937 , 0.00101818],\n",
       "       [0.00098366, 0.00104854, 0.00099469, 0.00093783, 0.00100902,\n",
       "        0.00097822, 0.00100993, 0.00102296, 0.00099408, 0.00101484],\n",
       "       [0.00098824, 0.00105208, 0.00099432, 0.00094128, 0.00100812,\n",
       "        0.00098409, 0.00100544, 0.00102468, 0.00100095, 0.00101768],\n",
       "       [0.00098511, 0.00105222, 0.00099741, 0.00094073, 0.00100408,\n",
       "        0.0009795 , 0.00100564, 0.00101944, 0.00099351, 0.00101575],\n",
       "       [0.00098758, 0.00105123, 0.00099326, 0.00094132, 0.00100592,\n",
       "        0.00098222, 0.00100733, 0.00102012, 0.00099394, 0.00101621],\n",
       "       [0.00098815, 0.00105283, 0.00099839, 0.00094037, 0.00100823,\n",
       "        0.00098273, 0.00100868, 0.00102378, 0.00099863, 0.00101722],\n",
       "       [0.00098665, 0.00105382, 0.00099259, 0.00093883, 0.00100721,\n",
       "        0.0009814 , 0.00100784, 0.0010222 , 0.00099751, 0.0010131 ],\n",
       "       [0.00098775, 0.00105083, 0.00099489, 0.00093973, 0.00100852,\n",
       "        0.00098175, 0.00100552, 0.00102185, 0.00099276, 0.00101584],\n",
       "       [0.00098694, 0.00105313, 0.00099529, 0.00093963, 0.00100516,\n",
       "        0.00098162, 0.00100719, 0.00101972, 0.00099665, 0.00101575],\n",
       "       [0.0009883 , 0.00105003, 0.00099402, 0.00094342, 0.00100789,\n",
       "        0.00097887, 0.00100226, 0.00102166, 0.00099871, 0.00101433],\n",
       "       [0.00098768, 0.00105055, 0.0009938 , 0.00094093, 0.00100914,\n",
       "        0.00097973, 0.00100723, 0.00101722, 0.00099348, 0.00101237],\n",
       "       [0.00098645, 0.00105054, 0.00099373, 0.0009397 , 0.00100705,\n",
       "        0.00097831, 0.00100883, 0.00101779, 0.0009985 , 0.00101304],\n",
       "       [0.00098281, 0.00104949, 0.00099727, 0.00094201, 0.00100644,\n",
       "        0.0009777 , 0.00100822, 0.00101966, 0.00099598, 0.00101779],\n",
       "       [0.00098519, 0.00105174, 0.00099655, 0.00094251, 0.00100478,\n",
       "        0.00098126, 0.00100839, 0.00102295, 0.00099513, 0.00101653],\n",
       "       [0.00098968, 0.00105089, 0.00099646, 0.00094206, 0.00100374,\n",
       "        0.00098194, 0.00100826, 0.00101606, 0.00099605, 0.00101897],\n",
       "       [0.00098734, 0.00105212, 0.00099262, 0.00094184, 0.00100566,\n",
       "        0.00098134, 0.00100792, 0.0010228 , 0.00099781, 0.00101483],\n",
       "       [0.00098379, 0.00104985, 0.00099327, 0.00094021, 0.00100862,\n",
       "        0.00097881, 0.00100974, 0.00101995, 0.00099678, 0.00101118],\n",
       "       [0.00098715, 0.00105421, 0.00099423, 0.00094204, 0.00100967,\n",
       "        0.00097966, 0.00100587, 0.0010203 , 0.00099863, 0.00101334],\n",
       "       [0.00098548, 0.00104955, 0.00099638, 0.00094087, 0.00100849,\n",
       "        0.00098504, 0.00100806, 0.00102261, 0.00099398, 0.0010167 ],\n",
       "       [0.00098871, 0.00105026, 0.00099044, 0.00094119, 0.00100928,\n",
       "        0.00098305, 0.00100634, 0.00101852, 0.0009984 , 0.00101554],\n",
       "       [0.00098509, 0.00105425, 0.00099485, 0.00094114, 0.00100398,\n",
       "        0.00097951, 0.00100901, 0.00101992, 0.00099758, 0.00101821],\n",
       "       [0.0009856 , 0.00104951, 0.0009953 , 0.00094152, 0.00100654,\n",
       "        0.0009812 , 0.00100754, 0.00101969, 0.00099317, 0.00101531],\n",
       "       [0.00098745, 0.00105448, 0.00099522, 0.00094174, 0.00100845,\n",
       "        0.00098045, 0.00100735, 0.00102214, 0.00099469, 0.00101657],\n",
       "       [0.00098574, 0.00105346, 0.00099245, 0.00094337, 0.00100706,\n",
       "        0.0009837 , 0.00100522, 0.0010223 , 0.00099356, 0.00101587],\n",
       "       [0.00098628, 0.00104835, 0.000993  , 0.00094432, 0.00100611,\n",
       "        0.00098127, 0.00100497, 0.00101993, 0.00099573, 0.00101501],\n",
       "       [0.0009867 , 0.00105049, 0.00099696, 0.00094252, 0.00100721,\n",
       "        0.00097931, 0.00100771, 0.00102069, 0.00099945, 0.00101604],\n",
       "       [0.00098306, 0.00105108, 0.00099321, 0.00093935, 0.00100725,\n",
       "        0.00097971, 0.00100572, 0.00101983, 0.00099433, 0.00101366],\n",
       "       [0.00098701, 0.00105206, 0.00099275, 0.00094161, 0.00099928,\n",
       "        0.00098144, 0.00100936, 0.00102131, 0.0009938 , 0.00101665],\n",
       "       [0.00098659, 0.00105467, 0.00099607, 0.00094264, 0.00100456,\n",
       "        0.00098218, 0.0010034 , 0.00101947, 0.00099789, 0.00101805],\n",
       "       [0.00098764, 0.00105286, 0.0009981 , 0.00094087, 0.00100427,\n",
       "        0.00097948, 0.0010077 , 0.00102002, 0.00099639, 0.00101462],\n",
       "       [0.00098709, 0.00105488, 0.00099182, 0.00094168, 0.00100667,\n",
       "        0.00097826, 0.00100294, 0.00101824, 0.00099765, 0.00101918],\n",
       "       [0.00098682, 0.00105222, 0.00099528, 0.00094158, 0.00100892,\n",
       "        0.00098192, 0.00100722, 0.0010199 , 0.00099802, 0.00101685],\n",
       "       [0.00098825, 0.00105253, 0.00099303, 0.0009403 , 0.00100705,\n",
       "        0.00098067, 0.00100683, 0.00102197, 0.00099632, 0.00101365],\n",
       "       [0.00098515, 0.00104909, 0.00099397, 0.00094133, 0.00100577,\n",
       "        0.00097972, 0.00100645, 0.0010188 , 0.00099374, 0.00101498],\n",
       "       [0.0009864 , 0.00104804, 0.00099375, 0.00094018, 0.00100673,\n",
       "        0.00097814, 0.00100549, 0.00102133, 0.00099688, 0.0010154 ],\n",
       "       [0.00098839, 0.00105274, 0.00099278, 0.0009397 , 0.00100569,\n",
       "        0.0009818 , 0.00100511, 0.00102269, 0.00099595, 0.00101658],\n",
       "       [0.00098867, 0.0010527 , 0.00099272, 0.00093925, 0.0010066 ,\n",
       "        0.00098159, 0.00100892, 0.00101915, 0.00099701, 0.00101466],\n",
       "       [0.00098674, 0.0010486 , 0.00098729, 0.00094008, 0.00100735,\n",
       "        0.00098322, 0.00100834, 0.00102128, 0.000995  , 0.00101246],\n",
       "       [0.00098305, 0.00105526, 0.00099422, 0.00094328, 0.00100687,\n",
       "        0.00097921, 0.00100622, 0.0010155 , 0.00099367, 0.00101563],\n",
       "       [0.00098868, 0.00105291, 0.00099325, 0.00094212, 0.00100993,\n",
       "        0.00098108, 0.00100402, 0.00102158, 0.00099705, 0.00101898],\n",
       "       [0.00098534, 0.0010505 , 0.00099213, 0.00094413, 0.00100477,\n",
       "        0.00097992, 0.00100559, 0.00101726, 0.00099409, 0.00101813],\n",
       "       [0.00098658, 0.00105249, 0.00099606, 0.00094236, 0.00100337,\n",
       "        0.00098047, 0.00100784, 0.00101721, 0.00099278, 0.001017  ],\n",
       "       [0.00098735, 0.00105201, 0.00099131, 0.00094102, 0.0010075 ,\n",
       "        0.00098082, 0.00100662, 0.00101624, 0.00099323, 0.00101815],\n",
       "       [0.00098649, 0.0010534 , 0.00099368, 0.00094013, 0.00100445,\n",
       "        0.00097541, 0.00100256, 0.00101868, 0.00099447, 0.00101455],\n",
       "       [0.0009858 , 0.00105198, 0.00099471, 0.0009401 , 0.00100749,\n",
       "        0.00098042, 0.00101071, 0.00101926, 0.00099647, 0.00101901],\n",
       "       [0.00098487, 0.00104873, 0.00099036, 0.00094081, 0.00100471,\n",
       "        0.00097654, 0.00100732, 0.00101848, 0.0009941 , 0.00101932],\n",
       "       [0.00098828, 0.00105298, 0.00099276, 0.00093949, 0.00100678,\n",
       "        0.00098213, 0.00100715, 0.00102174, 0.0009957 , 0.00101685],\n",
       "       [0.00098957, 0.00105232, 0.00098784, 0.00094432, 0.0010085 ,\n",
       "        0.00098098, 0.00101044, 0.00102101, 0.00099404, 0.00101304],\n",
       "       [0.00098442, 0.00105098, 0.0009919 , 0.00094011, 0.00100752,\n",
       "        0.00098019, 0.00100853, 0.00101939, 0.00099135, 0.00101902],\n",
       "       [0.00098544, 0.00104817, 0.00099143, 0.0009397 , 0.00101253,\n",
       "        0.00098217, 0.00100762, 0.00102043, 0.00099405, 0.00101327],\n",
       "       [0.00098761, 0.00105304, 0.00099371, 0.0009378 , 0.001006  ,\n",
       "        0.00097998, 0.00100787, 0.00102061, 0.00099605, 0.00101782],\n",
       "       [0.00098622, 0.00104936, 0.00098973, 0.000941  , 0.00100717,\n",
       "        0.00098268, 0.00100635, 0.00102288, 0.00099635, 0.00101617],\n",
       "       [0.00098911, 0.00105007, 0.00099298, 0.00094209, 0.00100543,\n",
       "        0.00098241, 0.00100998, 0.00102207, 0.00099606, 0.00101434],\n",
       "       [0.00098594, 0.00105538, 0.00099488, 0.00094283, 0.00100726,\n",
       "        0.00097983, 0.00100247, 0.00101991, 0.00099394, 0.00101868],\n",
       "       [0.00098893, 0.0010517 , 0.0009943 , 0.00094051, 0.00100684,\n",
       "        0.00098147, 0.00100542, 0.00102088, 0.0009938 , 0.00101519],\n",
       "       [0.00099019, 0.00104725, 0.0009942 , 0.00094255, 0.0010045 ,\n",
       "        0.00098177, 0.00100914, 0.0010177 , 0.00099292, 0.00101322],\n",
       "       [0.00098432, 0.0010506 , 0.00099378, 0.00094309, 0.00100693,\n",
       "        0.00098012, 0.00100806, 0.00102083, 0.0009942 , 0.00101533],\n",
       "       [0.00098728, 0.00105355, 0.00099328, 0.00094361, 0.00100501,\n",
       "        0.00097936, 0.00100521, 0.00101987, 0.00099489, 0.00101518],\n",
       "       [0.00098546, 0.00105567, 0.00099346, 0.00094102, 0.0010082 ,\n",
       "        0.00098401, 0.00100624, 0.00102105, 0.00099941, 0.00101669],\n",
       "       [0.00098795, 0.00105123, 0.00099435, 0.00094196, 0.00100664,\n",
       "        0.00098188, 0.00100774, 0.00102141, 0.00099497, 0.00101068],\n",
       "       [0.00098994, 0.00105304, 0.00099377, 0.00093897, 0.00100768,\n",
       "        0.00098148, 0.00100856, 0.00101975, 0.00099715, 0.00101786],\n",
       "       [0.00098564, 0.00105119, 0.00099354, 0.00094002, 0.00100513,\n",
       "        0.00098176, 0.00100794, 0.00101589, 0.00099423, 0.00101623],\n",
       "       [0.00098606, 0.00105235, 0.00099355, 0.00094034, 0.00100448,\n",
       "        0.00098172, 0.00100694, 0.00101928, 0.00099686, 0.00101668],\n",
       "       [0.00098668, 0.00105415, 0.0009912 , 0.00094476, 0.0010036 ,\n",
       "        0.00098189, 0.00100698, 0.00101862, 0.00099781, 0.00101659],\n",
       "       [0.00098311, 0.00105149, 0.00099044, 0.00094173, 0.00100759,\n",
       "        0.00097818, 0.0010079 , 0.00101971, 0.00099338, 0.0010147 ],\n",
       "       [0.00098577, 0.00105172, 0.00099215, 0.0009416 , 0.00100638,\n",
       "        0.00098017, 0.00100594, 0.00102172, 0.00099708, 0.0010149 ],\n",
       "       [0.00098509, 0.00105032, 0.00099525, 0.00094051, 0.00100966,\n",
       "        0.00098079, 0.00100856, 0.00102025, 0.0009963 , 0.00101248],\n",
       "       [0.00098635, 0.00104953, 0.00099711, 0.00094157, 0.001007  ,\n",
       "        0.00098093, 0.00100856, 0.00101989, 0.0009917 , 0.00101809],\n",
       "       [0.00098749, 0.00105195, 0.00099494, 0.00094053, 0.00100778,\n",
       "        0.00098174, 0.00100882, 0.00101787, 0.00099402, 0.00101586],\n",
       "       [0.00098375, 0.00104931, 0.00099401, 0.00094031, 0.00100836,\n",
       "        0.00097888, 0.00100363, 0.00102366, 0.00099683, 0.00101944],\n",
       "       [0.00098762, 0.0010523 , 0.00099588, 0.00094113, 0.00100346,\n",
       "        0.0009794 , 0.00100933, 0.00101703, 0.00099513, 0.00102002],\n",
       "       [0.00098453, 0.00105303, 0.00099092, 0.00094079, 0.00100753,\n",
       "        0.00097873, 0.00100112, 0.00102034, 0.00099233, 0.00101833],\n",
       "       [0.00098609, 0.00105002, 0.00099445, 0.00094127, 0.00100595,\n",
       "        0.00098036, 0.00101151, 0.00102166, 0.0009943 , 0.00101341],\n",
       "       [0.00098491, 0.00105617, 0.00099578, 0.00094033, 0.00100526,\n",
       "        0.00097726, 0.00100601, 0.00101575, 0.00099276, 0.00101588],\n",
       "       [0.00098935, 0.00105597, 0.00099554, 0.00094253, 0.00100513,\n",
       "        0.00097987, 0.00100363, 0.00101941, 0.00099418, 0.00102021],\n",
       "       [0.00099045, 0.00105176, 0.00099046, 0.0009399 , 0.00101101,\n",
       "        0.00098299, 0.00100832, 0.00102109, 0.00099694, 0.00101366],\n",
       "       [0.00098763, 0.0010565 , 0.00099452, 0.00094385, 0.00100878,\n",
       "        0.00098122, 0.00100598, 0.00102225, 0.0009938 , 0.00101627],\n",
       "       [0.00098816, 0.00105045, 0.00099472, 0.00094139, 0.00100916,\n",
       "        0.00098116, 0.00100545, 0.00102132, 0.00099513, 0.00101522],\n",
       "       [0.00098667, 0.00105456, 0.00099601, 0.00094018, 0.00100358,\n",
       "        0.00097968, 0.00100781, 0.00101925, 0.00099491, 0.00101978],\n",
       "       [0.00098405, 0.00105451, 0.0009936 , 0.00093728, 0.00100624,\n",
       "        0.00098038, 0.00100529, 0.00102296, 0.00099856, 0.00101723],\n",
       "       [0.00098739, 0.00105212, 0.00099667, 0.00093965, 0.00100673,\n",
       "        0.00098232, 0.00100597, 0.0010192 , 0.00099147, 0.00101627],\n",
       "       [0.00099027, 0.00105251, 0.00099245, 0.00094255, 0.00100472,\n",
       "        0.00098292, 0.00100818, 0.00102076, 0.00099364, 0.00101527],\n",
       "       [0.00098268, 0.00105079, 0.00099569, 0.00094139, 0.00100579,\n",
       "        0.00097842, 0.0010046 , 0.00102221, 0.0009989 , 0.00101745],\n",
       "       [0.00098874, 0.00105145, 0.00098974, 0.00094311, 0.00100918,\n",
       "        0.00098296, 0.00100737, 0.00102184, 0.00099313, 0.00101642],\n",
       "       [0.00098845, 0.00105237, 0.00099179, 0.0009425 , 0.0010079 ,\n",
       "        0.00098236, 0.00100589, 0.0010194 , 0.00099409, 0.00101619],\n",
       "       [0.00098922, 0.00104876, 0.00099047, 0.00093848, 0.00101081,\n",
       "        0.00098229, 0.0010045 , 0.00101927, 0.00099938, 0.00101848]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기울기(gradient) 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-ed25599258c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-76f75ead8aa7>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-db097f9a8a66>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, X)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_numerical_gradient_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-975a317cd149>\u001b[0m in \u001b[0;36m_numerical_gradient_1d\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mfxh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# f(x-h)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfxh1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfxh2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-76f75ead8aa7>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mloss_W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-76f75ead8aa7>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-76f75ead8aa7>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "t = np.random.rand(100, 10)\n",
    "\n",
    "grads = net.numerical_gradient(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads['W1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads['b1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAEvCAYAAAAtufaDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQGklEQVR4nO3de4xUdZrG8ecRxBvGoLaEOO72LFGzxmRRC7IGNayjRP1HCc5mSJy40QTjJRFjzBr+cLxkDTGDo0ZjggvKJo7jKOAlMbNeYuKaeCu8gngPji0IbVRUokyAd//oYreBbs6Pruo+/cL3k5CqOv3277yHQz+cc+pXpx0RAoCsDqi7AQBoByEGIDVCDEBqhBiA1AgxAKkRYgBSGzuSKzv66KOju7t7JFcJYB+xcuXKryOia9flbYWY7fMk3S1pjKT/jIgFe6rv7u5Ws9lsZ5UA9lO2Px9o+ZBPJ22PkXSfpPMlnSRpju2ThjoeAAxFO9fEpkn6JCI+i4i/SfqTpAs70xYAlGknxI6V9EW/1z2tZQAwYtoJMQ+wbLcPYtqea7tpu9nb29vG6gBgd+2EWI+k4/q9/oWkdbsWRcSiiGhERKOra7c3FgCgLe2E2BuSjrf9S9vjJP1G0lOdaQsAygx5ikVEbLV9jaT/Vt8UiyURsbpjnQFAgbbmiUXEM5Ke6VAvALDX+NgRgNQIMQCpEWIAUiPEAKRGiAFIjRADkBohBiA1QgxAaoQYgNQIMQCpEWIAUiPEAKRGiAFIjRADkBohBiA1QgxAaoQYgNQIMQCpEWIAUiPEAKRGiAFIjRADkBohBiA1QgxAaoQYgNQIMQCpEWIAUiPEAKRGiAFIjRADkBohBiA1QgxAaoQYgNQIMQCpEWIAUiPEAKRGiAFIjRADkBohBiC1sXU3gNy2b99eWbNly5YR6GRnS5cuLarbvHlzUd37779fVHfXXXdV1syfP79orHvvvbeo7pBDDqmsWbhwYdFYV155ZVHdaNJWiNleK+kHSdskbY2IRieaAoBSnTgS+5eI+LoD4wDAXuOaGIDU2g2xkPSs7ZW25w5UYHuu7abtZm9vb5urA4CdtRti0yPiVEnnS7ra9lm7FkTEoohoRESjq6urzdUBwM7aCrGIWNd63ChphaRpnWgKAEoNOcRsH2b78B3PJc2UtKpTjQFAiXbenZwoaYXtHeP8MSL+0pGuAKDQkEMsIj6T9E8d7AWD2LRpU2XNtm3bisZ65513iuqeffbZorrvvvuusmbRokVFY41m3d3dRXXXX399Zc3ixYuLxjriiCOK6s4888zKmrPPPrtorIyYYgEgNUIMQGqEGIDUCDEAqRFiAFIjxACkRogBSI0QA5AaIQYgNW5PXaOenp6iuilTplTWfPvtt+22s1864ICy/8dLZ9mX3Cr68ssvLxrrmGOOKaobP358Zc2+fAcZjsQApEaIAUiNEAOQGiEGIDVCDEBqhBiA1AgxAKkRYgBSI8QApMaM/RodddRRRXUTJ06srNkXZuzPnDmzqK7k72358uVFYx100EFFdTNmzCiqw8jjSAxAaoQYgNQIMQCpEWIAUiPEAKRGiAFIjRADkBohBiA1JrvWqORWxpL00EMPVdY8/vjjRWOdfvrpRXWzZ88uqitxxhlnFNU9+eSTRXXjxo2rrPnqq6+Kxrr77ruL6jB6cSQGIDVCDEBqhBiA1AgxAKkRYgBSI8QApEaIAUiNEAOQGiEGIDVHxIitrNFoRLPZHLH17U+2bNlSVFcy212S5s+fX1R3xx13VNa8+OKLRWOdddZZRXXYP9leGRGNXZdXHonZXmJ7o+1V/ZYdafs52x+3Hid0umEAKFFyOvmQpPN2WXajpBci4nhJL7ReA8CIqwyxiHhJ0je7LL5Q0tLW86WSLupwXwBQZKgX9idGxHpJaj0e07mWAKDcsL87aXuu7abtZm9v73CvDsB+ZqghtsH2JElqPW4crDAiFkVEIyIaXV1dQ1wdAAxsqCH2lKRLW88vlVR2NzsA6LCSKRaPSHpF0om2e2xfLmmBpHNtfyzp3NZrABhxlbenjog5g3zpVx3uBQD2GvfY30ccdNBBHR1vwoTOzV++5557iurOPPPMojrb7bSDfQyfnQSQGiEGIDVCDEBqhBiA1AgxAKkRYgBSI8QApEaIAUiNEAOQGjP2MaB58+YV1b3++uuVNStWrCgaa/Xq1UV1J598clEd9g8ciQFIjRADkBohBiA1QgxAaoQYgNQIMQCpEWIAUiPEAKTmiBixlTUajWg2myO2Pgy/b77Z9ZfD727y5MlFYx155JFFdRddVP0L56dPn1401qxZs4rquCV2/WyvjIjGrss5EgOQGiEGIDVCDEBqhBiA1AgxAKkRYgBSI8QApEaIAUiNEAOQGjP2MexKbmEtSeedd15R3aZNm9ppZydLliwpqps9e3ZR3fjx49tpB3vAjH0A+yRCDEBqhBiA1AgxAKkRYgBSI8QApEaIAUiNEAOQGiEGILWxdTeAfd+0adOK6lavXl1Ud91111XWPPbYY0VjXXbZZUV1n376aVHdDTfcUFlz+OGHF42FMpVHYraX2N5oe1W/ZTfb/tL2260/FwxvmwAwsJLTyYckDfShtj9ExJTWn2c62xYAlKkMsYh4SVL17+UCgBq0c2H/Gtvvtk43JwxWZHuu7abtZm9vbxurA4DdDTXE7pc0WdIUSeslLRysMCIWRUQjIhpdXV1DXB0ADGxIIRYRGyJiW0Rsl/SApLK3nwCgw4YUYrYn9Xs5S9KqwWoBYDhVzhOz/YikGZKOtt0j6XeSZtieIikkrZV0xTD2CACD4vbUSOfnn3+urHn11VeLxjrnnHOK6kp/Ti6++OLKmkcffbRoLOyM21MD2CcRYgBSI8QApEaIAUiNEAOQGiEGIDVCDEBqhBiA1AgxAKlxe2qkc/DBB1fWzJgxo2isMWPGFNVt3bq1qO6JJ56orPnwww+LxjrxxBOL6vZ3HIkBSI0QA5AaIQYgNUIMQGqEGIDUCDEAqRFiAFIjxACkRogBSI0Z+xg11q1bV1S3fPnyyppXXnmlaKzSmfilpk6dWllzwgkndHSd+zuOxACkRogBSI0QA5AaIQYgNUIMQGqEGIDUCDEAqRFiAFIjxACkxox9tKW3t7ey5r777isa68EHHyyq6+npKarrpNJ78Xd3d1fW2G6zG/THkRiA1AgxAKkRYgBSI8QApEaIAUiNEAOQGiEGIDVCDEBqTHbdz/z4449FdU8//XRR3a233lpZ89FHHxWNVYezzz67qG7BggVFdaeddlo77WAIKo/EbB9n+0Xba2yvtn1ta/mRtp+z/XHrccLwtwsAOys5ndwq6fqI+EdJ/yzpatsnSbpR0gsRcbykF1qvAWBEVYZYRKyPiDdbz3+QtEbSsZIulLS0VbZU0kXD1SQADGavLuzb7pZ0iqTXJE2MiPVSX9BJOqbTzQFAleIQsz1e0jJJ8yLi+734vrm2m7abJXc8AIC9URRitg9UX4A9HBE7fnPpBtuTWl+fJGnjQN8bEYsiohERja6urk70DAD/p+TdSUtaLGlNRNzZ70tPSbq09fxSSU92vj0A2LOSeWLTJf1W0nu2324tmy9pgaQ/275c0l8l/Xp4WgSAwVWGWES8LGmwW1H+qrPtAMDeYcZ+Aps3b66s+eKLL4rGuuSSS4rq3nrrraK6OsycObOy5pZbbikaa+rUqUV13FJ69OKzkwBSI8QApEaIAUiNEAOQGiEGIDVCDEBqhBiA1AgxAKkRYgBSY8b+MPjpp5+K6ubNm1dU9/LLL1fWfPDBB0Vj1eGCCy4oqrvpppuK6qZMmVJZc+CBBxaNhfw4EgOQGiEGIDVCDEBqhBiA1AgxAKkRYgBSI8QApEaIAUiNya4ta9euLaq7/fbbK2uef/75orE+//zzoro6HHrooUV1t912W2XNVVddVTTWuHHjiuqA/jgSA5AaIQYgNUIMQGqEGIDUCDEAqRFiAFIjxACkRogBSI0QA5AaM/Zbli1bVlS3ePHiYe5kd6eeemplzZw5c4rGGju2bJfPnTu3qO7ggw8uqgOGC0diAFIjxACkRogBSI0QA5AaIQYgNUIMQGqEGIDUCDEAqRFiAFJzRIzYyhqNRjSbzRFbH4B9h+2VEdHYdXnlkZjt42y/aHuN7dW2r20tv9n2l7bfbv25YDgaB4A9Kfkg3VZJ10fEm7YPl7TS9nOtr/0hIn4/fO0BwJ5VhlhErJe0vvX8B9trJB073I0BQIm9urBvu1vSKZJeay26xva7tpfYntDh3gCgUnGI2R4vaZmkeRHxvaT7JU2WNEV9R2oLB/m+ubabtpu9vb0daBkA/l9RiNk+UH0B9nBELJekiNgQEdsiYrukByRNG+h7I2JRRDQiotHV1dWpvgFAUtm7k5a0WNKaiLiz3/JJ/cpmSVrV+fYAYM9K3p2cLum3kt6z/XZr2XxJc2xPkRSS1kq6Ylg6BIA9KHl38mVJHuBLz3S+HQDYO3zsCEBqhBiA1AgxAKkRYgBSI8QApEaIAUiNEAOQGiEGIDVCDEBqhBiA1AgxAKkRYgBSI8QApEaIAUiNEAOQGiEGIDVCDEBqhBiA1AgxAKk5IkZuZXavpM93WXy0pK9HrInOy96/lH8bsvcv5d+Gkej/7yNit9/7OKIhNhDbzYho1NpEG7L3L+Xfhuz9S/m3oc7+OZ0EkBohBiC10RBii+puoE3Z+5fyb0P2/qX821Bb/7VfEwOAdoyGIzEAGLLaQsz2ebY/tP2J7Rvr6qMdttfafs/227abdfdTwvYS2xttr+q37Ejbz9n+uPU4oc4e92SQ/m+2/WVrP7xt+4I6e9wT28fZftH2GturbV/bWp5pHwy2DbXsh1pOJ22PkfSRpHMl9Uh6Q9KciHh/xJtpg+21khoRkWZ+j+2zJP0o6b8i4uTWsjskfRMRC1r/oUyIiH+vs8/BDNL/zZJ+jIjf19lbCduTJE2KiDdtHy5ppaSLJP2b8uyDwbbhX1XDfqjrSGyapE8i4rOI+JukP0m6sKZe9isR8ZKkb3ZZfKGkpa3nS9X3D3JUGqT/NCJifUS82Xr+g6Q1ko5Vrn0w2DbUoq4QO1bSF/1e96jGv4Q2hKRnba+0PbfuZtowMSLWS33/QCUdU3M/Q3GN7Xdbp5uj9lSsP9vdkk6R9JqS7oNdtkGqYT/UFWIeYFnGt0mnR8Spks6XdHXrVAcj735JkyVNkbRe0sJ626lme7ykZZLmRcT3dfczFANsQy37oa4Q65F0XL/Xv5C0rqZehiwi1rUeN0paob7T5Iw2tK5z7LjesbHmfvZKRGyIiG0RsV3SAxrl+8H2ger74X84Ipa3FqfaBwNtQ137oa4Qe0PS8bZ/aXucpN9IeqqmXobE9mGti5qyfZikmZJW7fm7Rq2nJF3aen6ppCdr7GWv7fjhb5mlUbwfbFvSYklrIuLOfl9Ksw8G24a69kNtk11bb7/eJWmMpCUR8R+1NDJEtv9BfUdfkjRW0h8zbIPtRyTNUN9dBzZI+p2kJyT9WdLfSfqrpF9HxKi8eD5I/zPUdwoTktZKumLH9aXRxvYZkv5H0nuStrcWz1ffNaUs+2CwbZijGvYDM/YBpMaMfQCpEWIAUiPEAKRGiAFIjRADkBohBiA1QgxAaoQYgNT+F88EC7GughqkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "image = np.reshape(image1, [28, 28])\n",
    "plt.imshow(image, cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_per_epoch = max(train_size / batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-2397dc4dcb32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# 기울기 구하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# 기울기 방향으로 learning_rate만큼 가중치 갱신\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-76f75ead8aa7>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-db097f9a8a66>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, X)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_numerical_gradient_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-975a317cd149>\u001b[0m in \u001b[0;36m_numerical_gradient_1d\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtmp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_val\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mfxh1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# f(x+h)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-76f75ead8aa7>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mloss_W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-76f75ead8aa7>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-76f75ead8aa7>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(iters_num):\n",
    "    print(i)\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 구하기\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 기울기 방향으로 learning_rate만큼 가중치 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 손실함수 값 구하기\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        # train 정확도\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        # test 정확도\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        \n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
